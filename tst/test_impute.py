"""
TODO:
* add test for repository
* add behavior for time
DONE:
* create artificial example with tabular prediction
* add one sparse model
* test behavior
* implement impute logic
"""
import numpy as np
import pandas as pd

from tabrepo import EvaluationRepository
from tabrepo.contexts.context_artificial import load_repo_artificial, load_context_artificial
from tabrepo.predictions import TabularPredictionsMemmap
from tabrepo.predictions.tabular_predictions import TabularPredictionsDict, TabularModelPredictions, \
    TabularPredictionsInMemory
from tabrepo.utils.test_utils import generate_artificial_dict

num_models = 13
num_folds = 3
dataset_shapes = {
    "d1": ((20,), (50,)),
    "d2": ((10,), (5,)),
    "d3": ((4, 3), (8, 3)),
}
models = [f"{i}" for i in range(num_models)]

def test_keep_only_models_in_both_validation_and_test():
    pred_dict = generate_artificial_dict(num_folds, models, dataset_shapes)
    pred_dict["d2"][1]['pred_proba_dict_val'].pop("2")
    TabularModelPredictions._keep_only_models_in_both_validation_and_test(pred_dict)

    # check that the intersection works as expected, model "2" should not be present in the test split as it was
    # absent from the validation split
    assert "2" not in pred_dict["d2"][1]['pred_proba_dict_test']


def test_tabular_predictions():
    pred_dict = generate_artificial_dict(num_folds, models, dataset_shapes)

    # remove the second model from the second dataset and the second fold
    pred_dict["d2"][1]['pred_proba_dict_val'].pop("2")
    # pred_dict["d2"][1]['pred_proba_dict_test'].pop("2")

    # TODO proper tmpdir
    preds = TabularPredictionsMemmap.from_dict(pred_dict, output_dir='/tmp/foo')
    pred_expected = preds.predict_val(dataset="d2", fold=1, models=["3"], model_fallback="3")
    pred_obtained = preds.predict_val(dataset="d2", fold=1, models=["2"], model_fallback="3")
    assert np.allclose(pred_expected, pred_obtained)


def test_repository():
    zsc, configs_full, pred_proba, zeroshot_gt = load_context_artificial()

    # remove NeuralNetFastAI_r1 from fold 1 of abalone...
    pred_dict = pred_proba.pred_dict
    pred_dict["abalone"][1]['pred_proba_dict_val'].pop("NeuralNetFastAI_r1")
    repo = EvaluationRepository(
        zeroshot_context=zsc,
        tabular_predictions=TabularPredictionsMemmap.from_dict(pred_dict, "/tmp/foo2"),
        ground_truth=zeroshot_gt,
    )

    # ... and make sure we retrieve the result of the fallback when querying results from missing NeuralNetFastAI_r1
    repo.set_config_fallback("NeuralNetFastAI_r2")
    pred_expected = repo.predict_val(dataset="abalone", fold=1, config="NeuralNetFastAI_r2")
    pred_obtained = repo.predict_val(dataset="abalone", fold=1, config="NeuralNetFastAI_r1")
    assert np.allclose(pred_expected, pred_obtained)